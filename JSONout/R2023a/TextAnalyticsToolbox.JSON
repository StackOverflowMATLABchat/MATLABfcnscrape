[
	"abbreviations",
	"addDependencyDetails",
	"addDocument",
	"addEntityDetails",
	"addLanguageDetails",
	"addLemmaDetails",
	"addPartOfSpeechDetails",
	"addSentenceDetails",
	"addTypeDetails",
	"bagOfNgrams",
	"bagOfWords",
	"bleuEvaluationScore",
	"bm25Similarity",
	"characterCategories",
	"contains",
	"containsNgrams",
	"containsWords",
	"context",
	"corpusLanguage",
	"correctSpelling",
	"cosineSimilarity",
	"decodeHTMLEntities",
	"doc2cell",
	"doc2sequence",
	"docfun",
	"doclength",
	"editDistance",
	"editDistanceSearcher",
	"encode",
	"erasePunctuation",
	"eraseTags",
	"eraseURLs",
	"extractFileText",
	"extractHTMLText",
	"extractSummary",
	"fastTextWordEmbedding",
	"findElement",
	"fitlda",
	"fitlsa",
	"getAttribute",
	"hex",
	"hmmEntityModel",
	"htmlTree",
	"ind2word",
	"ismember",
	"ismissing",
	"isVocabularyWord",
	"join",
	"joinWords",
	"knnsearch",
	"ldaModel",
	"lexrankScores",
	"logp",
	"lower",
	"lsaModel",
	"mecabOptions",
	"mmrScores",
	"normalizeWords",
	"pdfinfo",
	"plus",
	"predict",
	"predict",
	"rakeKeywords",
	"rangesearch",
	"ratioSentimentScores",
	"readPDFFormData",
	"readWordEmbedding",
	"regexprep",
	"removeDocument",
	"removeEmptyDocuments",
	"removeInfrequentNgrams",
	"removeInfrequentWords",
	"removeLongWords",
	"removeNgrams",
	"removeShortWords",
	"removeStopWords",
	"removeWords",
	"replace",
	"replaceNgrams",
	"replaceWords",
	"resume",
	"rougeEvaluationScore",
	"sentenceChart",
	"splitGraphemes",
	"splitParagraphs",
	"splitSentences",
	"stopWords",
	"string",
	"string",
	"string",
	"textanalytics.ja.mecabToLemma",
	"textanalytics.ja.mecabToNER",
	"textanalytics.ja.mecabToPOS",
	"textanalytics.unicode.nfc",
	"textanalytics.unicode.nfd",
	"textanalytics.unicode.nfkc",
	"textanalytics.unicode.nfkd",
	"textanalytics.unicode.UTF32",
	"textrankKeywords",
	"textrankScores",
	"textscatter",
	"textscatter3",
	"tfidf",
	"tokenDetails",
	"tokenizedDocument",
	"topkngrams",
	"topkwords",
	"topLevelDomains",
	"trainHMMEntityModel",
	"trainWordEmbedding",
	"transform",
	"upper",
	"vaderSentimentScores",
	"vec2word",
	"word2ind",
	"word2vec",
	"wordcloud",
	"wordCloudCounts",
	"wordEmbedding",
	"wordEmbeddingLayer",
	"wordEncoding",
	"writeTextDocument",
	"writeWordEmbedding"
]
